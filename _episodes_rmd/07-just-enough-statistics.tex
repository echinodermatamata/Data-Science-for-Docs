% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\title{Just Enough Statistics}
\author{}
\date{\vspace{-2.5em}}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Just Enough Statistics},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\begin{document}
\maketitle

\hypertarget{lesson}{%
\subsection{Lesson}\label{lesson}}

\hypertarget{the-big-picture}{%
\subsubsection{The big picture}\label{the-big-picture}}

In general, we are attempting to answer a research question by
collecting data from a \emph{sample} of a \emph{population}.

Data collection consists of measuring the values of several
\emph{variables} for each member of the population.

First, we gain insight into the data we have collected by inspecting it,
organising it, summarising it. This is \emph{descriptive statistics}.

Then, we use the data to draw conclusions about the population from
which the sample is collected, and to test the reliability of those
conclusions. This is \emph{inferential statistics}.

\hypertarget{statistics-hypothesis-testing}{%
\subsubsection{Statistics != Hypothesis
Testing}\label{statistics-hypothesis-testing}}

Often, when people think of statistics, they think ``what test should I
do.'' Testing procedures, including null hypothesis significance testing
(NHST), are a relatively small part of statistics. Scientific discovery
should be much broader than simply asking ``what test should I do''. The
best approach is to formalise a research question \emph{before}
collecting data, and then approach someone (e.g.~a statistician) who can
help formulate a method to answer it. This might involve working with
clinicians, scientist, trialists and methodologists. Whatever you do,
don't just collect data, and then look at a flow chart to find out what
test you should perform. This is a terrible way to do science.

\hypertarget{descriptive-statistics}{%
\subsubsection{Descriptive statistics}\label{descriptive-statistics}}

\hypertarget{measure-types}{%
\paragraph{Measure types}\label{measure-types}}

Variables may use the following systems of measure: - Binary: yes/no
e.g.~is the patient alive or dead - Count: naturally bound at zero
e.g.~daily A\&E admissions - Continuous: e.g.~Age, height, weight -
Discrete - Nominal: e.g.~eye colour - Ordinal: e.g.~likert approval
scale

Continuous variables can be measured with arbitrary precision. Think of
\textbf{age}: we typically measure it to the nearest year, but in theory
we could measure this in seconds, nanoseconds or even more accurately.
Continuous variables contain the maximum amount of statistical
information. If we discretise a continuous variable, e.g.~place it into
groupings like deciles, then we discard information. This should be
avoided.

Discrete variables take only a fixed number of possible values. Look at
the \textbf{sex} variable in our dataset which only takes the values
``F'' and ``M''. There is no natural ordering here so the values are
nominal. Discrete values that have a natural order (e.g.~a likert scale
with ``bad'', ``moderate'', ``good'') are known as ordinal values.

Different types of data are optimally presented in different ways. For
example, binary data is presented succinctly as the proportion of
``yes'', while continuous data might be better presented as the average
result.

\hypertarget{distributions}{%
\paragraph{Distributions}\label{distributions}}

When trying to convey information about a variable, we want to explain
succinctly what values the variable takes, and with what frequency this
occurs. This is most commonly performed via a histogram.

Let's think about the values \textbf{sodium} in our data can take, and
how often it takes each one. We can visualise this with a histogram:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(na)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{binwidth =} \DecValTok{2}\NormalTok{,}
    \AttributeTok{colour =} \StringTok{"black"}\NormalTok{,}
    \AttributeTok{fill =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{180}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Sodium (mmol/L)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 5 rows containing non-finite values (stat_bin).
\end{verbatim}

\begin{verbatim}
## Warning: Removed 2 rows containing missing values (geom_bar).
\end{verbatim}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/sodium\_hist.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

This is fairly symmetric, like a normal distribution, but the peak is a
little too high, and the tails are a little too heavy.

Our dataset contains 5000 rows of observations, but imagine if it
contained 1 million rows, or even more. We would start to build up a
more and more detailed picture of how often different sodium occur in
our data. This would be the \emph{distribution} of the sodium variable.
Let's overlay a normal distribution so we can see how close it is.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ na)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{..density..),}
                 \AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{180}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{), }
                 \AttributeTok{colour =} \StringTok{"black"}\NormalTok{,}
                 \AttributeTok{fill =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
\FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dnorm, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{na), }\AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{na)), }\AttributeTok{colour =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{180}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 5 rows containing non-finite values (stat_bin).
\end{verbatim}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/sodium\_hist\_norm.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

As you can see, the peak is a little too high, and the tails too heavy.
It is wise not to assume normality, just because the sample size is
large.

Let's explore some other variables in the data; ``potassium'' and
``id''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(k)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{binwidth =} \FloatTok{0.2}\NormalTok{,}
    \AttributeTok{colour =} \StringTok{"black"}\NormalTok{,}
    \AttributeTok{fill =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/k\_hist.png", width = 16, height = 9, units = "cm")}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{parse\_number}\NormalTok{(id))) }\SpecialCharTok{+} \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{colour =} \StringTok{"black"}\NormalTok{,}
    \AttributeTok{fill =} \StringTok{"white"}\NormalTok{, }\AttributeTok{bins =} \DecValTok{30}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-4-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ggsave("./images/id.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

\textbf{potassium} could be described as right-tailed, or
\emph{right-skewed}. It might seem a bit irrelevant to plot a histogram
for the \textbf{id} variable, but this is a great example of the
\emph{uniform distribution} (where all states of the variable are
equally likely).

The normal distribution is perhaps the most well known distribution. We
see this bell shaped curve throughout nature, wherever small additions
and subtractions are being made. For example, in the many thousands of
aggregate genetic and environmental factors that determine an
individuals height.

\begin{figure}
\centering
\includegraphics{https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/2000px-Normal_Distribution_PDF.svg.png}
\caption{Several normal distributions}
\end{figure}

We can see how the centre-point of the bell curve shifts right and left
as the mean of the distribution changes. This is why the mean is known
is a measure of location. The thinness or fatness of the distribution
alters as we change the standard deviation. This is why the standard
deviation is a measure of spread. It is a measure of how spread out the
data is around the mean.

A key question to ask yourself as you inspect the histograms for your
data is, does this variable look like the normal distribution? That is,
if we kept taking more-and-more observations in our experiment, would
the histogram we obtain look more-and-more like a bell-curve? Normally
distributed data is convenient to present and analyse, as is can be
described perfectly by only two numbers: the mean and the sd.

\hypertarget{describing-location}{%
\paragraph{Describing Location}\label{describing-location}}

The location is the measure of central tenancy of the data. It is the
peak of the bell curve for example.

\begin{itemize}
\tightlist
\item
  Mean = sum of all data points/number of data points
\item
  Median = middle data point, if all data were arranged in order on a
  line
\item
  Mode = most common data point
\end{itemize}

\begin{figure}
\centering
\includegraphics{https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Comparison_mean_median_mode.svg/2000px-Comparison_mean_median_mode.svg.png}
\caption{Mean, median, mode}
\end{figure}

For normally distributed data, all 3 measures of location align.

\hypertarget{exercise}{%
\paragraph{Exercise}\label{exercise}}

Try plotting histograms, calculate the mean and median for the following
data columns: - \texttt{wbc}, \texttt{crp}, \texttt{platelets},
\texttt{hb} Are the mean and median good at describing these
distributions You can use the following functions: \texttt{mean()} and
\texttt{median()}

\hypertarget{describing-spread}{%
\paragraph{Describing Spread}\label{describing-spread}}

For measuring the `spread' of the data:

\begin{itemize}
\tightlist
\item
  For normally-distributed data, use standard deviation
\item
  for non normally-distributed data, the lower and upper quartiles are
  often used i.e if all data were arranged in order on a line, the
  values in the 25th and 75th centiles. Similarly the median was just
  the 50th centile
\end{itemize}

Take care not to confused the interquartile range (a single number) and
the lower and upper quartiles (two numbers). Both are used to describe
spread.

\hypertarget{descriptive-statistics-in-one-go}{%
\paragraph{Descriptive Statistics in one
go}\label{descriptive-statistics-in-one-go}}

You can calculate lots of useful descriptive statistics in one fell
swoop using just one simple R function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      ph_abg         hco3_abg         temp_c         temp_nc     
##  Min.   :6.760   Min.   : 5.20   Min.   :25.70   Min.   :23.40  
##  1st Qu.:7.310   1st Qu.:20.90   1st Qu.:35.90   1st Qu.:36.10  
##  Median :7.360   Median :23.30   Median :36.30   Median :36.60  
##  Mean   :7.355   Mean   :23.26   Mean   :36.31   Mean   :36.37  
##  3rd Qu.:7.410   3rd Qu.:25.52   3rd Qu.:36.90   3rd Qu.:37.00  
##  Max.   :7.620   Max.   :65.30   Max.   :39.20   Max.   :39.70  
##                                                                 
##       urea         creatinine              na              k        
##  Min.   : 0.600   Length:5000        Min.   : 99.0   Min.   :2.000  
##  1st Qu.: 4.200   Class :character   1st Qu.:136.0   1st Qu.:4.000  
##  Median : 6.100   Mode  :character   Median :139.0   Median :4.400  
##  Mean   : 8.212                      Mean   :138.3   Mean   :4.456  
##  3rd Qu.: 9.700                      3rd Qu.:141.0   3rd Qu.:4.900  
##  Max.   :56.500                      Max.   :164.0   Max.   :7.800  
##                                                                     
##        hb             wbc           neutrophil       platelets    
##  Min.   :  5.5   Min.   : 0.000   Min.   : 0.010   Min.   :  0.0  
##  1st Qu.: 92.0   1st Qu.: 8.887   1st Qu.: 6.895   1st Qu.:142.0  
##  Median :108.0   Median :11.800   Median :10.000   Median :198.0  
##  Mean   :107.0   Mean   :12.889   Mean   :10.759   Mean   :220.1  
##  3rd Qu.:123.0   3rd Qu.:15.500   3rd Qu.:13.600   3rd Qu.:269.0  
##  Max.   :171.0   Max.   :59.300   Max.   :56.510   Max.   :989.0  
##                                                                   
##       crp             chemo         chronic_rrt       metastatic    
##  Min.   :  0.10   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:  9.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median : 46.00   Median :0.0000   Median :0.0000   Median :0.0000  
##  Mean   : 78.61   Mean   :0.4074   Mean   :0.2082   Mean   :0.2148  
##  3rd Qu.:107.00   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000  
##  Max.   :541.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##                                                                     
##     radiotx           apache          medical           system      
##  Min.   :0.0000   Min.   : -1.00   Min.   :0.0000   Min.   : 1.000  
##  1st Qu.:0.0000   1st Qu.: 11.00   1st Qu.:0.0000   1st Qu.: 2.000  
##  Median :0.0000   Median : 15.00   Median :0.0000   Median : 2.000  
##  Mean   :0.2168   Mean   : 19.47   Mean   :0.4916   Mean   : 3.288  
##  3rd Qu.:0.0000   3rd Qu.: 20.00   3rd Qu.:1.0000   3rd Qu.: 4.000  
##  Max.   :1.0000   Max.   :119.00   Max.   :1.0000   Max.   :10.000  
##                                                                     
##      height          weight       elective_surgical
##  Min.   :1.450   Min.   : 50.00   Min.   :0.0000   
##  1st Qu.:1.600   1st Qu.: 65.00   1st Qu.:0.0000   
##  Median :1.700   Median : 75.00   Median :0.0000   
##  Mean   :1.686   Mean   : 76.61   Mean   :0.4466   
##  3rd Qu.:1.750   3rd Qu.: 90.00   3rd Qu.:1.0000   
##  Max.   :1.900   Max.   :150.00   Max.   :1.0000   
##                                                    
##   arrival_dttm                 discharge_dttm               
##  Min.   :2014-01-01 00:35:32   Min.   :2014-01-02 01:06:16  
##  1st Qu.:2015-07-02 12:22:18   1st Qu.:2015-07-08 04:39:20  
##  Median :2016-12-06 16:14:27   Median :2016-12-11 07:06:45  
##  Mean   :2016-11-30 19:31:11   Mean   :2016-12-05 04:01:23  
##  3rd Qu.:2018-04-30 15:20:14   3rd Qu.:2018-05-05 04:12:20  
##  Max.   :2019-09-24 00:13:38   Max.   :2019-10-07 01:43:08  
##                                                             
##       dob             vital_status           sex                 id           
##  Min.   :1934-01-01   Length:5000        Length:5000        Length:5000       
##  1st Qu.:1944-03-26   Class :character   Class :character   Class :character  
##  Median :1954-07-17   Mode  :character   Mode  :character   Mode  :character  
##  Mean   :1956-08-23                                                           
##  3rd Qu.:1968-01-02                                                           
##  Max.   :1999-09-22                                                           
##  NA's   :1                                                                    
##   lactate_1hr      lactate_6hr      lactate_12hr         los        
##  Min.   : 0.200   Min.   : 0.100   Min.   : 0.000   Min.   : 0.000  
##  1st Qu.: 1.100   1st Qu.: 0.800   1st Qu.: 0.500   1st Qu.: 1.000  
##  Median : 1.500   Median : 1.300   Median : 0.900   Median : 3.000  
##  Mean   : 2.074   Mean   : 1.805   Mean   : 1.375   Mean   : 4.354  
##  3rd Qu.: 2.300   3rd Qu.: 2.000   3rd Qu.: 1.600   3rd Qu.: 5.000  
##  Max.   :17.900   Max.   :20.700   Max.   :21.400   Max.   :31.000  
##                                                                     
##       age       
##  Min.   :20.00  
##  1st Qu.:50.00  
##  Median :60.00  
##  Mean   :60.27  
##  3rd Qu.:70.00  
##  Max.   :80.00  
##  NA's   :1
\end{verbatim}

It is important to always plot your data, as these summary terms seldom
fully describe your data. See the example below. The data points
presented all share the same mean, standard distribution and
correlation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"./img/anscombes\_quartet.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{./img/anscombes_quartet.png}

\hypertarget{inferential-statistics}{%
\subsection{Inferential Statistics}\label{inferential-statistics}}

The following core concepts are central to inferential statistics, and
often misunderstood: - Power - P values - Confidence intervals.

If we can leave today with a strong intuition for these concepts, the
rest will come easily.

All these concepts are part of the frequentist approach to statistics.
In that they are hypothetical quantities that are valid in the long run,
if we were to repeat an experiment infinitely many times. Usually we can
only perform 1 experiment (like a randomised controlled trial), and so
this point is often confused.

We will use simulation to visualise what these different quantities
refer to.

\hypertarget{power}{%
\subsubsection{Power}\label{power}}

The power of a test (often written as a percentage) is the probability
that the test will reject the test hypothesis at a pre-specified
significance level. This significance level is usually (and arbitrarily)
set to 0.05.

\begin{quote}
In plain English. If I were to repeat a study 1000 times, and I have
80\% power at the 0.05 significance level, \emph{and} a true effect
exists. I would expect around 800 of the experiments to have a p value
\textless= 0.05, and around 200 of the experiments to have a p value
\textgreater{} 0.05
\end{quote}

Power is a pre-study probability. It is defined, and fixed before
starting an experiment. Occasionally you will see ``post-hoc power''
which is meaningless and to be avoided.

We can set up a simulation where we sample 8 men and 8 women from the
general public. We want to know, ``are the heights in these two groups
different?''. Perhaps this comes from our research question: ``Are men
taller than women?''.

In the simulation we can fix the average \emph{population} male and
female height to be 1.75 m and 1.6 m respectively. Normally we can't
ever know the population quantities (thats why we are sampling).
Simulation allows us to fix these before performing an experiement, so
we can observe how the experiement performs.

\begin{quote}
In pain English. We have rigged an experiment, so that we take random
samples of men and women, where we \emph{know} than men are 15 cm taller
than women.
\end{quote}

So we have performed 1000 simulated experiments, and placed the results
into a data-frame \texttt{sim}. Each experiement is a sample of 8 men,
and 8 women, who we compare with a t-test. This asks the question:
``does the average height of this sample men, equal the average height
of this sample of women?''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(}\AttributeTok{signficant =}\NormalTok{ p\_value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tally}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   signficant     n
##   <lgl>      <int>
## 1 FALSE        166
## 2 TRUE         834
\end{verbatim}

By counting the number of experiements with a p value \textless= 0.05,
we can see the proportion that are ``significant''. Thus, the power to
detect a 15 cm difference in height, at the 0.05 significance, for a
sample size of 8 subjects in each group is around 80\%.

Even though we know that the underlying populations differ by 15 cm (we
fixed that), we were unable to find this difference in 20\% of cases.
These 20\% are ``false negatives''. There is a true difference, but we
did not detect it. The remaining 80\% are the true positives. This is
the direct interpretation of statistical power. This has happened
because even though our population averages are fixed, we are still
sampling randomly. And so by chance, some of these groups look very
similar. Occationally, by chance, we might sample a group of taller than
average women, who are of similar height to our sample of men.

Since we don't want to be wrong often, how might we increase the power?
For a given effect size (15 cm difference in our simulation), we can do
so by increasing the number of people in the study.

Let's look at how the power changes as we increase the number of people
in each group from 8 to 50.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(subjects) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarise}\NormalTok{(}\AttributeTok{significant =} \FunctionTok{sum}\NormalTok{(p\_value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ subjects, }\AttributeTok{y =}\NormalTok{ significant)) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \FloatTok{0.8}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{, }\AttributeTok{colour =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \FloatTok{0.9}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{, }\AttributeTok{colour =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Proportion of Experiments with P \textless{}= 0.05"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Number of subjects in each arm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-10-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/power1.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

We can see that in order to find a difference of 15 cm, we have about
80\% power with 8 subjects in each arm, and 90\% power with 10 subjects.
By the time we get to 30 subjects, we will seldom be unable to detect
the difference.

What if the effect size isn't fixed? Below is a plot that shows
different possibilities if we are sticking with 8 samples from each
group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pwr }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{delta }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.02}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.01}\NormalTok{)) \{}
\NormalTok{ delta }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(delta, i)}
\NormalTok{ pwr }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(pwr, }\FunctionTok{power.t.test}\NormalTok{(}\AttributeTok{n =} \DecValTok{8}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{sig.level =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{delta =}\NormalTok{ i)}\SpecialCharTok{$}\NormalTok{power)}
\NormalTok{\}}
\NormalTok{sim }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{effect\_size =}\NormalTok{ delta,}
  \AttributeTok{power =}\NormalTok{ pwr}
\NormalTok{)}

\NormalTok{sim }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ effect\_size, }\AttributeTok{y =}\NormalTok{ power)) }\SpecialCharTok{+} \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.2}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Effect size (cm)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Power curve for heights with 8 in each group"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/power\_curve.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

As you can see, statistical power is a function of both effect size, and
sample size.

\hypertarget{traps-to-avoid}{%
\paragraph{Traps to avoid}\label{traps-to-avoid}}

The power is not a direct probability in relation to an individual
experiment. For example, it is \emph{not} the probability that a
specific experiment performed is a true positive. The probability that
any specific experiment is a true positive is either 1 or 0, we just
don't know which.

Statistical significance is a messy topic. Statistical power gives us a
clue as to why we might regularly find that studies on the same topic
are in disagreement. Imagine two independent studies trying to
investigate the same issue (for example, early antibiotics in sepsis).
And they are both powered at 80\%. Let's assume for a moment, that early
antibiotics are beneficial (i.e.~the study would hope to have a positive
finding). Then the probability that both studies will have a p value
\textless= 0.05 will be \texttt{0.8*0.8\ =\ 0.64}. So there is only a
2/3rds chance that the studies will ``agree''. The chance that one will
be ``positive'' and the other be ``negative'' is
\texttt{2*0.8*0.2\ =\ 0.32}. So there is actually nearly a 1/3rd chance
that these studies will ``differ'' in their findings. Perhaps we should
not be so quick to point out where studies disagree, since this is
somewhat expected behaviour?

\hypertarget{p-values}{%
\subsubsection{P Values}\label{p-values}}

The p value is the probability of seeing data this or more extreme,
given that all your assumptions are true, and that \emph{the null
hypothesis is also true}. The p value is another hypothetical frequency
probability. It is another long running measure.

It is \emph{not} the probability of a false positive. The probability
that you are right or wrong about the interpretation of your findings,
is either 1 or 0, we just don't know which. If you were to repeat a null
experiment an infinite number of times (remember that the p value
\emph{assumes} the null hypothesis to be true), then the p value
converges to the proportion of false positives. Let's use simulation
again to show this.

Since the properties of the p value are most readily demonstrated under
the null condition, we will modify our experiment to sample 8 men, and
then 8 more men, both with average heights of 1.75 m. So we know a
priori, that there is no difference between these groups.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1000}\NormalTok{) \{}
\NormalTok{men\_a }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{8}\NormalTok{, }\FloatTok{1.75}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{men\_b }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{8}\NormalTok{, }\FloatTok{1.75}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{p\_values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(p\_values, }\FunctionTok{t.test}\NormalTok{(}\AttributeTok{x =}\NormalTok{ men\_a, }\AttributeTok{y =}\NormalTok{ men\_b, }\AttributeTok{paired =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{var.equal =} \ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{p.value)}
\NormalTok{\}}

\NormalTok{sim }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{trial\_number =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1000}\NormalTok{,}
    \AttributeTok{p\_value =}\NormalTok{ p\_values)}

\NormalTok{sim }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(}\AttributeTok{signficant =}\NormalTok{ p\_value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{tally}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   signficant     n
##   <lgl>      <int>
## 1 FALSE        947
## 2 TRUE          53
\end{verbatim}

As you can see around 5\% of the experiments came up ``significant''.
These are false positives by definition, since we have ``rigged'' the
study so that we know there isn't a difference. By chance, 5\% of these
samples were sufficiently different from one another. Perhaps one group
was slightly taller than average.

The p value is simply a measure of compatibility between your data and
your model (which includes all assumptions, including that the null
hypothesis is true). A p value close to 0 means the data is highly
incompatible with your model. Since your model includes the assumption
that the null hypothesis is true, it can act as evidence against the
null hypothesis. It might also mean that your study was improperly
designed, or that your other assumptions were false.

\hypertarget{traps-to-avoid-1}{%
\paragraph{Traps to avoid}\label{traps-to-avoid-1}}

A large p value does not mean \emph{no difference}. A large p value just
means that you couldn't detect a difference. It simply means that the
data is compatible with your model (which includes the assumption that
the null hypothesis is correct)

\hypertarget{confidence-intervals}{%
\subsubsection{Confidence Intervals}\label{confidence-intervals}}

Confidence intervals are another long running property of experiments.
They are based upon the p value, and define a range of values that are
compatible with the data.

We will run our simulations again, but this time perform 100 samples, so
the confidence intervals can be plotted more clearly. Let us run the
first experiment, where we sample men of height 1.75 m, and women of
height 1.6 m.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower\_ci }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{upper\_ci }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{p\_value }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{) \{}
\NormalTok{men }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{8}\NormalTok{, }\FloatTok{1.75}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{women }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{8}\NormalTok{, }\FloatTok{1.60}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{t\_test }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(}\AttributeTok{x =}\NormalTok{ men, }\AttributeTok{y =}\NormalTok{ women, }\AttributeTok{paired =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{var.equal =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{lower\_ci }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(lower\_ci, t\_test}\SpecialCharTok{$}\NormalTok{conf.int[}\DecValTok{1}\NormalTok{])}
\NormalTok{upper\_ci }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(upper\_ci, t\_test}\SpecialCharTok{$}\NormalTok{conf.int[}\DecValTok{2}\NormalTok{])}
\NormalTok{p\_value }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(p\_value, t\_test}\SpecialCharTok{$}\NormalTok{p.value)}
\NormalTok{\}}

\NormalTok{sim }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{trial\_number =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{,}
    \AttributeTok{p\_value =}\NormalTok{ p\_value,}
    \AttributeTok{lower\_ci =}\NormalTok{ lower\_ci,}
    \AttributeTok{upper\_ci =}\NormalTok{ upper\_ci)}

\NormalTok{sim }\OtherTok{\textless{}{-}}\NormalTok{ sim }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{significant =} \FunctionTok{if\_else}\NormalTok{(p\_value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{, }\StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}\NormalTok{),}
           \AttributeTok{contains\_dmu =} \FunctionTok{if\_else}\NormalTok{(}
\NormalTok{             lower\_ci }\SpecialCharTok{\textless{}=} \FloatTok{0.15} \SpecialCharTok{\&}\NormalTok{ upper\_ci }\SpecialCharTok{\textgreater{}=} \FloatTok{0.15}\NormalTok{, }\StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}
\NormalTok{           ))}

\NormalTok{sim }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ trial\_number)) }\SpecialCharTok{+}
    \FunctionTok{geom\_linerange}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ lower\_ci, }\AttributeTok{ymax =}\NormalTok{ upper\_ci, }\AttributeTok{colour =}\NormalTok{ significant)) }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \FloatTok{0.15}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlab}\NormalTok{(}\StringTok{"Sample repeat (1 to 100)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Difference in means (m)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Sample confidence intervals for population effect size of 0.15 m"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_brewer}\NormalTok{(}\AttributeTok{palette =} \StringTok{"Set1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/ci1.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

As you can see, around 80\% of our samples, we regarded as
``significant'' findings in that they rejected the null hypothesis. This
is statistical power in action again. But let us reformat the plot, to
show us which confidence intervals contain the true effect size.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ trial\_number)) }\SpecialCharTok{+}
    \FunctionTok{geom\_linerange}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ lower\_ci, }\AttributeTok{ymax =}\NormalTok{ upper\_ci, }\AttributeTok{colour =}\NormalTok{ contains\_dmu)) }\SpecialCharTok{+}
    \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+}
    \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \FloatTok{0.15}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{xlab}\NormalTok{(}\StringTok{"Sample repeat (1 to 100)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Difference in means (m)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Sample confidence intervals for population effect size of 0.15 m"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_brewer}\NormalTok{(}\AttributeTok{palette =} \StringTok{"Set2"}\NormalTok{,}
                      \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{title =} \StringTok{"contains }\SpecialCharTok{\textbackslash{}n}\StringTok{true effect"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-just-enough-statistics_files/figure-latex/unnamed-chunk-14-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#ggsave("./images/ci2.png", width = 16, height = 9, units = "cm")}
\end{Highlighting}
\end{Shaded}

Now we can see that around 5\% of our samples contain the true
difference of 0.15 m. Note that for each individual exeriment, the
chance that the confidence interval contains the true difference is
either 0 or 1, we just don't know which. Also, The midpoint of the
confidence interval is no more likely than any other. All the confidence
interval shows us, is a range of values that are \emph{compatible} with
your sample. In the long run, there is a 95\% chance that the confidence
interval will contain the true value.

\hypertarget{wrapping-up}{%
\subsubsection{Wrapping Up}\label{wrapping-up}}

This has been a brief visit into descriptive and inferential statistics.
The former tries to describe the data, through location, spread and
distribtuions, and the latter tries to understand the data.

\end{document}
